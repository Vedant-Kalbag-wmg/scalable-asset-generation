{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install librosa numpy pandas demucs soundfile pyfluidsynth\n",
    "! sudo yum install libsndfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "import subprocess as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Source Separation using Demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DeMixedAudio4():\n",
    "    sample_rate: int\n",
    "    bass : np.ndarray\n",
    "    drums : np.ndarray\n",
    "    other : np.ndarray\n",
    "    vocals : np.ndarray\n",
    "\n",
    "@dataclass\n",
    "class DeMixedAudio6():\n",
    "    sample_rate: int\n",
    "    bass : np.ndarray\n",
    "    drums : np.ndarray\n",
    "    other : np.ndarray\n",
    "    vocals : np.ndarray\n",
    "    piano : np.ndarray\n",
    "    guitar : np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sp.run([\"python3\", \"-m\", \"demucs.separate\", \"-o\", \"../resources/tmp\", \"-n\", model, path_to_file])- Does the model work with different sample rates? YES\n",
    "- Does the model output have the same sample rate as the input? - NO: ALWAYS 44100\n",
    "- If so TODO: find a way to find the input native sample rate of the audio and use this to re-load the stems\n",
    "\n",
    "- The output volumes are different since the input audio is z score normalised by demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file_name = os.path.basename(os.path.join(os.getcwd(),'..','resources/test_file.wav'))\n",
    "# sp.run([\"python3\", \"-m\", \"demucs.separate\", \"-o\", \"../resources/tmp\", \"-n\", \"htdemucs_6s\", os.path.join(os.getcwd(),'..','resources/test_file.wav')])\n",
    "# print(\"Demucs done, loading files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x,sr = librosa.load(os.path.join(os.getcwd(),'..','resources/Nightmare.mp3'),sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('../resources/Nightmare.wav',x, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stems(path_to_file,model='htdemucs',delete_temp_files=True):\n",
    "    file_name = os.path.basename(path_to_file)\n",
    "    sp.run([\"python3\", \"-m\", \"demucs.separate\", \"-o\", \"../resources/tmp\", \"-n\", model, path_to_file])\n",
    "    print(\"Demucs done, loading files\")\n",
    "    stems={}\n",
    "    if model in ['htdemucs','htdemucs_ft']:\n",
    "        for stem in ['bass','drums','other','vocals']:\n",
    "            x,sr = librosa.load(os.path.join(\"../resources/tmp\", model,file_name[:file_name.find('.')],f\"{stem}.wav\"), sr=None)\n",
    "            stems[stem] = x\n",
    "        if delete_temp_files:\n",
    "            print(\"Deleting temp files\")\n",
    "            rmtree(f\"../resources/tmp/{model}/{file_name[:file_name.find('.')]}\")\n",
    "        return DeMixedAudio4(sr, bass=stems['bass'], drums=stems['drums'], other=stems['other'], vocals=stems['vocals'])#stems\n",
    "    elif model == 'htdemucs_6s':\n",
    "        for stem in ['bass','drums','other','vocals','piano', 'guitar']:\n",
    "            x,sr = librosa.load(os.path.join(\"../resources/tmp\", model,file_name[:file_name.find('.')],f\"{stem}.wav\"), sr=None)\n",
    "            stems[stem] = x\n",
    "        if delete_temp_files:\n",
    "            print(\"Deleting temp files\")\n",
    "            rmtree(f\"../resources/tmp/{model}/{file_name[:file_name.find('.')]}\")\n",
    "        return DeMixedAudio6(sr, bass=stems['bass'], drums=stems['drums'], other=stems['other'], vocals=stems['vocals'], piano=stems['piano'], guitar=stems['guitar'])#stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffprobe: error while loading shared libraries: libopenh264.so.5: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /home/ec2-user/SageMaker/scalable-asset-generation/resources/tmp/htdemucs_ft\n",
      "Separating track /home/ec2-user/SageMaker/scalable-asset-generation/src/../resources/Nightmare.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 380.25/380.25 [00:16<00:00, 22.82seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 380.25/380.25 [00:15<00:00, 24.76seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 380.25/380.25 [00:15<00:00, 24.61seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 380.25/380.25 [00:15<00:00, 24.56seconds/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demucs done, loading files\n"
     ]
    }
   ],
   "source": [
    "song = get_stems(os.path.join(os.getcwd(),'..','resources/Nightmare.wav'), model='htdemucs_ft', delete_temp_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeMixedAudio4(sample_rate=44100, bass=array([-9.1552734e-05, -9.1552734e-05, -9.1552734e-05, ...,\n",
       "       -1.0681152e-04, -1.9836426e-04, -2.5939941e-04], dtype=float32), drums=array([-6.1035156e-05, -6.1035156e-05, -6.1035156e-05, ...,\n",
       "       -4.2724609e-04, -4.4250488e-04, -8.5449219e-04], dtype=float32), other=array([-1.2207031e-04, -4.5776367e-05, -3.0517578e-05, ...,\n",
       "       -1.2207031e-04, -1.2008667e-02, -6.7749023e-03], dtype=float32), vocals=array([-6.1035156e-05, -6.1035156e-05, -6.1035156e-05, ...,\n",
       "       -9.0805054e-02, -2.1102905e-02,  4.2022705e-02], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pop2Piano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt-get install -y fluidsynth\n",
    "!git clone https://github.com/sweetcocoa/pop2piano/\n",
    "!cd pop2piano\n",
    "!pip install pretty-midi==0.2.9 omegaconf==2.1.1 youtube-dl==2021.12.17 transformers==4.16.1 pytorch-lightning==1.8.4 essentia==2.1b6.dev609 note-seq==0.0.3 pyFluidSynth==1.3.0\n",
    "!wget https://github.com/sweetcocoa/pop2piano/releases/download/dpi_2k_epoch/model-1999-val_0.67311615.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(\"pop2piano\")\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import soundfile as sf\n",
    "# from google.colab import files\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import note_seq\n",
    "\n",
    "from utils.dsp import get_stereo\n",
    "from utils.demo import download_youtube\n",
    "from transformer_wrapper import TransformerWrapper\n",
    "from midi_tokenizer import MidiTokenizer, extrapolate_beat_times\n",
    "from preprocess.beat_quantizer import extract_rhythm, interpolate_beat_times\n",
    "\n",
    "from mido import MidiFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# config = OmegaConf.load(\"pop2piano/config.yaml\")\n",
    "# wrapper = TransformerWrapper(config)\n",
    "# wrapper = wrapper.load_from_checkpoint(\"model-1999-val_0.67311615.ckpt\", config=config).to(device)\n",
    "# model = \"dpipqxiy\"\n",
    "\n",
    "# composer='composer1'\n",
    "# wrapper.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pm, composer, mix_path, midi_path = wrapper.generate(\n",
    "#     audio_path=os.path.join(os.getcwd(),'..','resources/test_file.wav'), \n",
    "#     composer=composer, \n",
    "#     model=model,\n",
    "#     show_plot=False, \n",
    "#     save_midi=True, \n",
    "#     save_mix=False, \n",
    "# )\n",
    "# # note_seq.plot_sequence(note_seq.midi_to_note_sequence(pm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_piano(path_to_file, composer='composer1'):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    config = OmegaConf.load(\"pop2piano/config.yaml\")\n",
    "    wrapper = TransformerWrapper(config)\n",
    "    wrapper = wrapper.load_from_checkpoint(\"model-1999-val_0.67311615.ckpt\", config=config).to(device)\n",
    "    model = \"dpipqxiy\"\n",
    "\n",
    "    wrapper.eval()\n",
    "    pm, composer, mix_path, midi_path = wrapper.generate(\n",
    "        audio_path=path_to_file, \n",
    "        composer=composer, \n",
    "        model=model,\n",
    "        show_plot=False, \n",
    "        save_midi=True, \n",
    "        save_mix=False, \n",
    "    )\n",
    "    midi_file = MidiFile(midi_path)\n",
    "    os.remove(midi_path)\n",
    "    \n",
    "    return midi_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "midi = get_piano('../resources/test_resources/test_file-48000.wav')\n",
    "midi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acapella = song.vocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acapella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stem gain testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyloudnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "meter = pyln.Meter(song.sample_rate) # create BS.1770 meter\n",
    "meter.integrated_loudness(song.vocals) # measure loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Original track loudness\n",
    "meter.integrated_loudness(librosa.load(os.path.join(os.getcwd(),'..','resources/test_file.wav'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reconstructed track loudness\n",
    "meter.integrated_loudness(song.vocals + song.other + song.bass + song.drums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,sr = librosa.load(os.path.join(os.getcwd(),'..','resources/test_file.wav'), sr=None)\n",
    "\n",
    "x_48k = librosa.resample(x, orig_sr=sr, target_sr=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('../resources/test_resources/test_file-48000.wav',x_48k, 48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test,sr_test = librosa.load('../resources/test_resources/test_file-48000.wav', sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song = get_stems(os.path.join(os.getcwd(),'..','resources/test_resources/test_file-48000.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humanization- https://github.com/erwald/rachel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path_to_song:str, output_folder_path:str, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf4c79542e7d10b0ff3d3e51bf4ffdbb3a1ac3d24233afb3e0a2f487d25ec48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
